{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"sentiment_scores_dates.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = df.progress_apply(lambda row: pd.to_datetime(row['datetime']).strftime('%d/%m/%Y'), axis=1)\n",
    "df['date_month'] = df.progress_apply(lambda row: pd.to_datetime(row['datetime']).strftime('%d/%m'), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('sentiment_scores_dates.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing distribution of scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# invite people for the party\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import locale\n",
    "locale.setlocale(locale.LC_ALL, \"pt_BR.utf8\")\n",
    "plt.rcParams.update({\n",
    "    'axes.formatter.use_locale' : True,\n",
    "})\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.fschuch.com/blog/2020/10/14/graficos-com-qualidade-de-publicacao-em-python-com-matplotlib/\n",
    "# define a pattern of dimensions for plots\n",
    "def get_figsize(columnwidth=4, wf=1.0, hf_rel=(5.0 ** 0.5 - 1.0) / 2.0, hf_abs=None, unit=\"inch\"):\n",
    "    # Dessa maneira, unit não será sensível a letras maiúsculas e minúsculas\n",
    "    unit = unit.lower()\n",
    "\n",
    "    # Converte unidades para polegadas, conforme esperado por Matplotlib\n",
    "    conversion = dict(inch=1.0, mm=25.4, cm=2.54, pt=72.0,)\n",
    "\n",
    "    if unit in conversion.keys():\n",
    "        fig_width = columnwidth / conversion[unit]\n",
    "        if hf_abs is not None:\n",
    "            fig_height = hf_abs / conversion[unit]\n",
    "    else:\n",
    "        raise ValueError(f\"unit deve ser: {conversion.keys()}\")\n",
    "\n",
    "    # A figura será apenas uma fração da largura útil da página\n",
    "    fig_width *= wf\n",
    "\n",
    "    # Caso hf_abs não seja definido, a altura será uma fração da largura\n",
    "    if hf_abs is None:\n",
    "        fig_height = fig_width * hf_rel\n",
    "\n",
    "    # Retorna a largura e altura especificada para a figura\n",
    "    return (fig_width, fig_height)\n",
    "\n",
    "plt.rcParams.update({\n",
    "    'figure.figsize' : get_figsize(columnwidth=455.0, unit='pt'),\n",
    "    #\n",
    "    \"axes.labelsize\": 12,\n",
    "    \"font.size\": 12,\n",
    "    \"legend.fontsize\": 12,\n",
    "    \"xtick.labelsize\": 12,\n",
    "    \"ytick.labelsize\": 12,\n",
    "})\n",
    "\n",
    "# if necessary a customization for each particular figure\n",
    "# fig, axes = plt.subplots(figsize=get_figsize(columnwidth=16, unit='cm', hf_rel=0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemplo salvando arquivo em vetorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.savefig('example_line.'+f, format=f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribuição dos scores (Sem normalização)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o ambiente do gráfico \n",
    "sns.set_style(\"white\")\n",
    "fig, ax = plt.subplots(1, 1, figsize=(15, 10))\n",
    "\n",
    "# Insere curva KDE (Kernel Density Estimation)\n",
    "g1 = sns.distplot(df[\"textblob_score\"], ax=ax, \n",
    "                  kde=True, hist=False, label='Textblob score')\n",
    "# Insere curva KDE (Kernel Density Estimation)\n",
    "g2 = sns.distplot(df[\"vader_score\"], ax=ax, \n",
    "                  kde=True, hist=False, label='Vader score')\n",
    "# Insere curva KDE (Kernel Density Estimation)\n",
    "g3 = sns.distplot(df[\"afinn_score\"], ax=ax, \n",
    "                  kde=True, hist=False, label='Afinn score')\n",
    "plt.legend()\n",
    "plt.savefig('1_scores_distribution.svg')\n",
    "plt.savefig('1_scores_distribution.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalização do score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.preprocessing import PowerTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = np.array(df['afinn_score']).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# squares_root\n",
    "def squareRoot(value):\n",
    "    if value > 0:\n",
    "        return np.sqrt(value)\n",
    "    if value < 0:\n",
    "        return np.sqrt(abs(value)) * (-1)\n",
    "    return 0\n",
    "\n",
    "squares = df.apply(lambda row: squareRoot(row['afinn_score']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Normalização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_afinn_score = df['afinn_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizado = MinMaxScaler(feature_range=(-1,1)).fit_transform(np.array(df_afinn_score).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Gráfico com normalização 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o ambiente do gráfico \n",
    "sns.set_style(\"white\")\n",
    "fig, ax = plt.subplots(1, 1, figsize=(15, 10))\n",
    "\n",
    "# Insere curva KDE (Kernel Density Estimation)\n",
    "g2 = sns.distplot(df[\"textblob_score\"], ax=ax, \n",
    "                  kde=True, hist=False, label='Textblob score')\n",
    "# Insere curva KDE (Kernel Density Estimation)\n",
    "g3 = sns.distplot(df[\"vader_score\"], ax=ax, \n",
    "                  kde=True, hist=False, label='Vader score')\n",
    "# Insere curva KDE (Kernel Density Estimation)\n",
    "g3 = sns.distplot(normalizado, ax=ax, \n",
    "                  kde=True, hist=False, label='Afinn score normalizado')\n",
    "plt.legend()\n",
    "plt.xlabel('Polaridade')\n",
    "plt.xlabel('Densidade')\n",
    "plt.savefig('2_scores_distribution.svg')\n",
    "plt.savefig('2_scores_distribution.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Gráfico com raiz quadrada e normalização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizadoComRaiz1 = MinMaxScaler(feature_range=(-1,1)).fit_transform(squares.values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o ambiente do gráfico \n",
    "sns.set_style(\"white\")\n",
    "fig, ax = plt.subplots(1, 1, figsize=(15, 10))\n",
    "\n",
    "# Insere curva KDE (Kernel Density Estimation)\n",
    "g2 = sns.distplot(df[\"textblob_score\"], ax=ax, \n",
    "                  kde=True, hist=False, label='Textblob')\n",
    "# Insere curva KDE (Kernel Density Estimation)\n",
    "g3 = sns.distplot(df[\"vader_score\"], ax=ax, \n",
    "                  kde=True, hist=False, label='Vader')\n",
    "# Insere curva KDE (Kernel Density Estimation)\n",
    "g3 = sns.distplot(normalizadoComRaiz1, ax=ax, \n",
    "                  kde=True, hist=False, label='Afinn (raíz + norm)')\n",
    "plt.legend()\n",
    "plt.xlabel('Polaridade')\n",
    "plt.xlabel('Densidade')\n",
    "plt.savefig('3_scores_distribution_raíz_e_normalização.svg')\n",
    "plt.savefig('3_scores_distribution_raíz_e_normalização.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Raíz quadrada e normalização 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squareRoot(value):\n",
    "    if value > 0:\n",
    "        return np.sqrt(value)\n",
    "    if value < 0:\n",
    "        return np.sqrt(abs(value)) * (-1)\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "squares2 = df.apply(lambda row: squareRoot(squareRoot(row['afinn_score'])), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizadoComRaiz2 = MinMaxScaler(feature_range=(-1,1)).fit_transform(squares2.values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "squares2 = df.apply(lambda row: squareRoot(squareRoot(row['afinn_score'])), axis=1)\n",
    "normalizadoComRaiz2 = MinMaxScaler(feature_range=(-1,1)).fit_transform(squares2.values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o ambiente do gráfico \n",
    "sns.set_style(\"white\")\n",
    "fig, ax = plt.subplots(1, 1, figsize=(15, 10))\n",
    "\n",
    "# Insere curva KDE (Kernel Density Estimation)\n",
    "g2 = sns.distplot(df[\"textblob_score\"], ax=ax, \n",
    "                  kde=True, hist=False, label='Textblob')\n",
    "# Insere curva KDE (Kernel Density Estimation)\n",
    "g3 = sns.distplot(df[\"vader_score\"], ax=ax, \n",
    "                  kde=True, hist=False, label='Vader')\n",
    "# Insere curva KDE (Kernel Density Estimation)\n",
    "g3 = sns.distplot(normalizadoComRaiz2, ax=ax, \n",
    "                  kde=True, hist=False, label='Afinn norm (2)')\n",
    "plt.legend()\n",
    "plt.xlabel('Polaridade')\n",
    "plt.ylabel('Densidade')\n",
    "plt.savefig('4_normalização_minmax_scale.svg')\n",
    "plt.savefig('4_normalização_minmax_scale.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['afinn_score_norm'] = normalizadoComRaiz2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Z-score normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zscoreNormalization(x, mean, std):\n",
    "    return (x-mean)/std\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean, std = np.mean(df['afinn_score']), np.std(df['afinn_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['afinn_zscored'] = df.apply(lambda row: zscoreNormalization(row['afinn_score'], mean, std), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o ambiente do gráfico \n",
    "sns.set_style(\"white\")\n",
    "fig, ax = plt.subplots(1, 1, figsize=(15, 10))\n",
    "\n",
    "# Insere curva KDE (Kernel Density Estimation)\n",
    "g2 = sns.distplot(df[\"textblob_score\"], ax=ax, \n",
    "                  kde=True, hist=False, label='Textblob')\n",
    "# Insere curva KDE (Kernel Density Estimation)\n",
    "g3 = sns.distplot(df[\"vader_score\"], ax=ax, \n",
    "                  kde=True, hist=False, label='Vader')\n",
    "# Insere curva KDE (Kernel Density Estimation)\n",
    "g3 = sns.distplot(df['afinn_zscored'], ax=ax, \n",
    "                  kde=True, hist=False, label='Afinn Z-score')\n",
    "plt.legend()\n",
    "plt.xlabel('Polaridade')\n",
    "plt.ylabel('Densidade')\n",
    "plt.savefig('5_afinn_zscore.svg')\n",
    "plt.savefig('5_afinn_zscore.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "afinn_zscored = np.array(df['afinn_zscored'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "afinn_zscored_norm = MinMaxScaler(feature_range=(-1,1)).fit_transform(afinn_zscored.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['afinn_zscored_norm'] = afinn_zscored_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o ambiente do gráfico \n",
    "sns.set_style(\"white\")\n",
    "fig, ax = plt.subplots(1, 1, figsize=(15, 10))\n",
    "\n",
    "# Insere curva KDE (Kernel Density Estimation)\n",
    "g2 = sns.distplot(df[\"textblob_score\"], ax=ax, \n",
    "                  kde=True, hist=False, label='Textblob')\n",
    "# Insere curva KDE (Kernel Density Estimation)\n",
    "g3 = sns.distplot(df[\"vader_score\"], ax=ax, \n",
    "                  kde=True, hist=False, label='Vader')\n",
    "# Insere curva KDE (Kernel Density Estimation)\n",
    "g3 = sns.distplot(df['afinn_zscored_norm'], ax=ax, \n",
    "                  kde=True, hist=False, label='Afinn Z-scored norm')\n",
    "plt.legend()\n",
    "plt.xlabel('Polaridade')\n",
    "plt.ylabel('Densidade')\n",
    "plt.savefig('6_afinn_zscore_norm.svg')\n",
    "plt.savefig('6_afinn_zscore_norm.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Textblob normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textblob_score = df['textblob_score']\n",
    "vader_score = df['vader_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textblob_norm = MinMaxScaler(feature_range=(-1,1)).fit_transform(textblob_score.values.reshape(-1,1))\n",
    "vader_norm = MinMaxScaler(feature_range=(-1,1)).fit_transform(vader_score.values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o ambiente do gráfico \n",
    "sns.set_style(\"white\")\n",
    "fig, ax = plt.subplots(1, 1, figsize=(15, 10))\n",
    "\n",
    "# Insere curva KDE (Kernel Density Estimation)\n",
    "g2 = sns.distplot(textblob_norm, ax=ax, \n",
    "                  kde=True, hist=False, label='Textblob')\n",
    "# Insere curva KDE (Kernel Density Estimation)\n",
    "g3 = sns.distplot(vader_norm, ax=ax, \n",
    "                  kde=True, hist=False, label='Vader')\n",
    "# Insere curva KDE (Kernel Density Estimation)\n",
    "g3 = sns.distplot(df['afinn_score_norm'], ax=ax, \n",
    "                  kde=True, hist=False, label='Afinn Z-score')\n",
    "plt.legend()\n",
    "plt.xlabel('Polaridade')\n",
    "plt.ylabel('Densidade')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine the sentiment\n",
    "def getScore(score):\n",
    "    if score < 0:\n",
    "        return 'Negative'\n",
    "    elif score == 0:\n",
    "        return 'Neutral'\n",
    "    else:\n",
    "        return 'Positive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create two new columns ‘Subjectivity’ & ‘Polarity’\n",
    "df['textBlob_subjectivity'] = df.progress_apply(lambda row: getSubjectivity(row['processed_text']), axis=1)\n",
    "df['textBlob_polarity'] = df.progress_apply(lambda row: getPolarity(row['processed_text']), axis=1)    \n",
    "df['textBlob_analysis'] = df.progress_apply(lambda row: getAnalysis(row['textBlob_polarity']), axis=1)\n",
    "\n",
    "df.to_csv('processed_text_withemojis_tb.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "#checks if value is string\n",
    "def checkIfValueIsString(test_string):\n",
    "    return isinstance(test_string, str)\n",
    "\n",
    "# create a function to get the subjectivity\n",
    "def getScores(text):\n",
    "    if (checkIfValueIsString(text) == True):\n",
    "        return analyzer.polarity_scores(text)\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "#Create two new columns ‘Subjectivity’ & ‘Polarity’\n",
    "df['vader_scores'] = df.progress_apply(lambda row: getScores(row['processed_text']), axis=1)\n",
    "\n",
    "df.to_csv('processed_text_withemojis_tb_vd.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['vader_neg'] = df.progress_apply(lambda row: row['vader_scores']['neg'], axis=1)\n",
    "df['vader_neu'] = df.progress_apply(lambda row: row['vader_scores']['neu'], axis=1)\n",
    "df['vader_pos'] = df.progress_apply(lambda row: row['vader_scores']['pos'], axis=1)\n",
    "df['vader_compound'] = df.progress_apply(lambda row: row['vader_scores']['compound'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['datetime', 'tweet_id', 'text', 'processed_text',\n",
    "       'textBlob_subjectivity', 'textBlob_polarity', \n",
    "       'textBlob_analysis','vader_compound']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('processed_text_withemojis_tb_vd.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Afinn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing necessary libraries\n",
    "from afinn import Afinn\n",
    "#instantiate afinn\n",
    "afn = Afinn()\n",
    "\n",
    "#checks if value is string\n",
    "def checkIfValueIsString(test_string):\n",
    "    return isinstance(test_string, str)\n",
    "\n",
    "# create a function to get the subjectivity\n",
    "def getAfinnScores(text):\n",
    "    if (checkIfValueIsString(text) == True):\n",
    "        return afn.score(text)\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "df['afinn_score'] = df.progress_apply(lambda row: getAfinnScores(row['processed_text']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('processed_text_withemojis_tb_vd_af.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['datetime'] = pd.to_datetime(df['datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = df[['datetime', 'tweet_id', 'text', 'text_lower', 'processed_text', 'textBlob_polarity', 'textBlob_analysis',\n",
    "       'vader_compound', 'afinn_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame.to_csv('processed_text_withemojis_scores.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delimitando tweets que realmente falam sobre o metaverso\n",
    "\n",
    "<blockquote>A força do tweet é determinada pela presença na pesquisa pelos usuários do Google Trends</blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Singular\n",
    "\n",
    "- metaverse is (139237)\n",
    "- what metaverse (2932)\n",
    "- is metaverse (31952)\n",
    "- what is metaverse (1794)\n",
    "- what metaverse is (884)\n",
    "\n",
    "Plural\n",
    "\n",
    "- metaverses are (604)\n",
    "- what metaverses (26)\n",
    "- are metaverses (58)\n",
    "- what are metaverses (0)\n",
    "- what metaverses are (9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<blockquote>Textos que fazem parte das pesquisas feitas por usuários são considerados fortes. Os tweets que contém os termos irão compor os tópicos fortemente relacionados</blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relatedTopics = 'metaverse is|what metaverse|is metaverse|what is metaverse|what metaverse is|metaverses are|what metaverses|are metaverses|what metaverses are'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('textBlob_analysis')['text'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tweets fracamente relacionados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[~df['text_lower'].str.contains(relatedTopics, regex=True)].set_index('datetime').groupby('textBlob_analysis')['text'].resample('M').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tweets fortemente relacionados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['text_lower'].str.contains(relatedTopics, regex=True)].set_index('datetime').groupby('textBlob_analysis')['text'].resample('M').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<blockquote>Como pode-se ver na tabela, para comentários fortemente relacionados ao metaverso, o número de comentários positivos supera o número de comentários negativos</blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: fazer merge com pd.apply e verificar de qual usuário cada base de dados pertence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=['datetime','tweet_id','username','like_count','username','user_followers','user_fav_count','is_verified','created_at']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_users = pd.read_csv(r'\\twitter-EDA\\tweets_preprocessing_norm\\tweets_preprocessed_english.csv', usecols=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging values of two columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = df[['tweet_id','textBlob_analysis']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_lower = df[['tweet_id','text_lower']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Inner join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_inner = pd.merge(left=merged_inner, right=text_lower, left_on='tweet_id', right_on='tweet_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Salvando sentimentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('sentiment_scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_sentiments = df[['processed_text','textblob_sentiment', 'vader_sentiment', 'afinn_sentiment','textblob_score', 'vader_score', 'afinn_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataframe_image as dfi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_column\", None)\n",
    "pd.set_option(\"display.max_colwidth\", 30)\n",
    "pd.set_option('display.width', -1)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_sentiments.columns = ['processed_text',\n",
    "       'textblob',\n",
    "       'vader',\n",
    "       'afinn',\n",
    "       't_score',\n",
    "       'v_score',\n",
    "       'a_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfi.export(\n",
    "    only_sentiments.head(20),\n",
    "    \"table_sentiment_and_score_.png\",\n",
    "    table_conversion=\"matplotlib\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Salvando normalização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strength = pd.read_csv(r'\\twitter-EDA\\tweets_studies_ranking\\strength.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strength.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_norm = strength[[\n",
    "       'processed_text',\n",
    "       'textblob_sentiment',\n",
    "       'vader_sentiment',\n",
    "       'afinn_sentiment',\n",
    "       'textblob_score',\n",
    "       'vader_score',\n",
    "       'afinn_score',\n",
    "       'afinn_score_norm']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_norm.columns = ['processed_text',\n",
    "       'textblob',\n",
    "       'vader',\n",
    "       'afinn',\n",
    "       't_score',\n",
    "       'v_score',\n",
    "       'a_score',\n",
    "       'a_norm_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfi.export(\n",
    "    only_norm.head(20),\n",
    "    \"table_afinn_norm.png\",\n",
    "    table_conversion=\"matplotlib\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d54245c670ff253d1204420841bd04192ea0c38e456268d4f3a24d97e25d8999"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
